---
title: "HW2_sz2800"
author: "Stephanie Zhen"
date: "3/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Loading libraries
```{r}
library(tidyverse)
library(ggplot2)
library(caret)
library(splines)
library(mgcv)
library(earth)
library(pdp)
```

### Loading Data and cleaning.
```{r}
college = read.csv("./College.csv") %>% 
  janitor::clean_names()

#Removing the 125 observation (Columbia) for training purposes. Also removed college names columns.
college_df1 = college[-125,-1]

#New dataset for the observation 125, Columbia for prediction purposes. Also removed college names columns.
college_cumc = college[125,-1]

#Looking at the structure of the data. 
#str(college_df1)
#summary(college_df1)
```

#### Step 0: Partitioning the outcome variable and the predictors. 

```{r}
#response variable for training
y = college_df1$outstate 

#matrix for predictors for training
x = model.matrix(outstate ~ ., data = college_df1)[,-1]

```


### Part A. Creating scatterplot of response vs all the predictors. 
```{r}
#Creating scatterplot of response vs predictors.
#There is a total of 16 predictors with 1 response variable, outstate. 
featurePlot(x, y, plot = "scatter", labels = c("", "Y"),
            type = c("p"), layout = c(4, 2))
```


### Part B: Smoothing Spline
```{r}
#Using range to predict df for smoothing spline
terminal_range = range(college_df1$terminal)

terminal_grid = seq(from = terminal_range[1],to = terminal_range[2])

#USing GCV to select the degree of freedom (trace of a smoother matrix)
fit_ss = smooth.spline(college_df1$terminal, college_df1$outstate)
fit_ss$df

pred_ss = predict(fit_ss,
                  x = terminal_grid)

pred_ss_df = data.frame(pred = pred_ss$y,
                        terminal = terminal_grid)

#plotting the fit
plot1 = ggplot(data = college_df1,
               aes(x = terminal,
                   y = outstate)) + 
        geom_point()
##Adding plot with smooth spline
plot1 + geom_line(aes(x = terminal,
                      y = pred),
                  data = pred_ss_df)
```
Through generalized cross validation the lambda selected was 0.03936 with degree of freedom 4.4686. Given these tuning parameter and the visual of the plot, it seems that the model is very smooth and fits the data. 


### Part C. GAM
```{r}
#Fitting a generalized additive model (GAM) using all the predictors.

set.seed(123)
control_1 = trainControl(method = "cv", number = 10)
gam_fit = train(x, y,
                method = "gam",
                tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE, FALSE)),
                trControl = control_1)
##best tune
gam_fit$bestTune
##final model
gam_fit$finalModel

plot(gam_fit$finalModel)
```
The sum of the degree of freedom is 55.98 (both parametric and non-parametric). The minimized GCV score is 2761951. GAM modeling smoothed out all the 16 variables using splines. 


### Part D. MARS
```{r}
#Fitting Multivariate adaptive regression splines (MARS)

#Grid searches to figure out tuning parameters.
mars_grid = expand.grid(degree = 1:2,
                        nprune = 2:10)

set.seed(123)
mars_fit = train(x, y,
                 method = "earth",
                 tuneGrid = mars_grid,
                 trControl = control_1)

ggplot(mars_fit)
mars_fit$finalModel
#Mars best tune and final model. 
mars_fit$bestTune
coef(mars_fit$finalModel)

#Partial dependence plot(pdp) of arbitary variable: room_board
partial_1 = partial(mars_fit,
                    pred.var = c("room_board"),
                    grid.resolution = 10) %>% 
  autoplot()
```
The final MARS model has 7 of the 16 predictors: room_board, expend, f_undergrad, perc_alumni, apps, enroll, accept. THe final model MARS model has only selected 10 of the 29 terms. 
The arbitary variable: room_board was used to create a partial dependence plot (pdp).


### Part E. Predicting Columbia's out of state tuition with GAM and MARS.
```{r}
gam_cumc = predict(gam_fit,
                   newdata = college_cumc)

mars_cumc = predict(mars_fit,
                    newdata = college_cumc)
```
 
The predicted out of state tuition for Columbia using the GAM model is 17728.51 dollars. The predicted out of state tuition for Columbia using the MARS model is 17469.90 dollars.

